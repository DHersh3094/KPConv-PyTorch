{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T17:33:57.599025Z",
     "start_time": "2024-12-10T17:33:57.593480Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import laspy as lp\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:33:58.901823Z",
     "start_time": "2024-12-10T17:33:58.898655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ALS_folder = '/home/davidhersh/Dropbox/Uni/ThesisHersh/ALS_data'\n",
    "output_folder = '/media/davidhersh/T7 Shield/pre-processing/tmp'"
   ],
   "id": "fdf22083b0d25cfe",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:37:09.976355Z",
     "start_time": "2024-12-10T17:37:09.972796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# k-fold\n",
    "n_splits = 5\n",
    "\n",
    "# Augmentation values\n",
    "min_subsample_distance = 0.2\n",
    "rotations = [-15, 15]"
   ],
   "id": "1a53d5a26594bca3",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:34:11.055073Z",
     "start_time": "2024-12-10T17:34:11.046063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def copy_folder(input_folder, output_folder=output_folder, point_threshold=2000, plot=True, redo=False):\n",
    "    \"\"\"\n",
    "    Copy single tree ALS files (ending with _g meaning ground classified) for a specific list of trees if they have a minimum point count\n",
    "    \"\"\"\n",
    "    \n",
    "    if redo:\n",
    "    \n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            \n",
    "        # Save figs\n",
    "        figdir = output_folder.replace('/tmp', '/processing_figures')\n",
    "        if not os.path.exists(figdir):\n",
    "            os.makedirs(figdir)\n",
    "        \n",
    "        # Only copy certain species\n",
    "        species_to_copy = [\n",
    "            \"PseMen\",\n",
    "            \"FagSyl\",\n",
    "            \"PinSyl\",\n",
    "            \"QueRub\",\n",
    "            \"PicAbi\",\n",
    "            \"QuePet\"\n",
    "        ]\n",
    "    \n",
    "        files = []\n",
    "        species_counter = Counter()\n",
    "        \n",
    "        for root, dirs, filenames in os.walk(input_folder):\n",
    "            for filename in filenames:\n",
    "                try:\n",
    "                    species_name = filename.split('_')[0]\n",
    "        \n",
    "                    # Study area BR06 has an issue with ground. Do not copy for further processing\n",
    "                    # File format: FagSyl_BR02_04_2019-07-05_q2_ALS-on_g.laz\n",
    "                    study_area = filename.split('_')[1] # BR02\n",
    "        \n",
    "                    if filename.endswith('ALS-on_g.laz') and species_name in species_to_copy and study_area != \"BR06\":\n",
    "                            las = lp.read(os.path.join(root, filename))\n",
    "                            number_of_nonground_points = len(las.points[las.classification !=2])\n",
    "                            if number_of_nonground_points >= point_threshold:\n",
    "                                species_counter[species_name] += 1\n",
    "                                files.append(os.path.join(root, filename))  # Store full file paths\n",
    "                                shutil.copyfile(os.path.join(root, filename), os.path.join(output_folder, filename))\n",
    "                except: \n",
    "                    pass\n",
    "        print(f'Copying {len(files)} files')\n",
    "        print(f'Unique species: {species_counter}')\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(figsize=(12,8))\n",
    "            plt.bar(species_counter.keys(), species_counter.values())\n",
    "            plt.ylabel('Number of trees')\n",
    "            plt.xlabel('Species')\n",
    "            plt.title(f\"Species with greater than {point_threshold} non-ground points\")\n",
    "            plt.savefig(os.path.join(figdir, f'species_count_greaterthan_{point_threshold}_points.png'), bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        return output_folder, species_counter\n",
    "    \n",
    "    else:\n",
    "        print(f'Skipping copying...')\n"
   ],
   "id": "2c2aaeabc71c8b32",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:34:12.228900Z",
     "start_time": "2024-12-10T17:34:12.219109Z"
    }
   },
   "cell_type": "code",
   "source": "copied_als_folder, species_counter = copy_folder(input_ALS_folder)",
   "id": "7861e14769e968f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping copying...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_384250/288200388.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcopied_als_folder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspecies_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy_folder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ALS_folder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "69194118c7837d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:34:21.917861Z",
     "start_time": "2024-12-10T17:34:21.912737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_hag(las_file):\n",
    "    las = lp.read(las_file)\n",
    "    x = las.x\n",
    "    y = las.y\n",
    "    z = las.z\n",
    "    \n",
    "    classification = las.classification\n",
    "    \n",
    "    ground_indices = classification == 2\n",
    "    x_ground = x[ground_indices]\n",
    "    y_ground = y[ground_indices]\n",
    "    z_ground = z[ground_indices]\n",
    "    \n",
    "    X, Y = np.meshgrid(x_ground, y_ground)\n",
    "    ground_interpolated = LinearNDInterpolator(list(zip(x_ground, y_ground)), z_ground)\n",
    "    Z = ground_interpolated(X, Y)\n",
    "    z_ground_at_points = ground_interpolated(x, y)\n",
    "    min_ground = np.nanmin(z_ground)\n",
    "    z_ground_at_points = np.where(np.isnan(z_ground_at_points), min_ground, z_ground_at_points)\n",
    "    hag = z - z_ground_at_points\n",
    "    las.z = hag\n",
    "    las = las[las.classification != 2]\n",
    "    \n",
    "    las.write(las_file)"
   ],
   "id": "4dca802491ce3d23",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:02:20.100603Z",
     "start_time": "2024-12-10T17:02:20.095798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Can do HAG calculation before split\n",
    "\n",
    "def convert_hag_to_z(input_folder=copied_als_folder, redo=False):\n",
    "    \n",
    "    if redo:\n",
    "        files = os.listdir(copied_als_folder)\n",
    "        for file in tqdm(files, desc='Processing files', unit='file'):\n",
    "            full_path = os.path.join(copied_als_folder, file)\n",
    "            calculate_hag(full_path)\n",
    "    else:\n",
    "        print(\"Skipping HAG step...\")\n",
    "        \n",
    "convert_hag_to_z(input_folder=copied_als_folder)"
   ],
   "id": "66dad78927f5f4a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping HAG step...\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:29:44.927827Z",
     "start_time": "2024-12-10T17:29:42.205776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stratified_k_fold_split(input_folder, output_folder, n_splits=5):\n",
    "    input_folder = copied_als_folder\n",
    "    output_folder = input_folder.replace('/tmp', '/kfolders')\n",
    "\n",
    "    files = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in os.listdir(input_folder):\n",
    "        class_name = file.split('_')[0] #Fagsyl etc...\n",
    "        files.append(os.path.join(input_folder, file))\n",
    "        labels.append(class_name)\n",
    "    class_counts = Counter(labels)\n",
    "    print(f'Class counts: {class_counts}')\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=32)\n",
    "    \n",
    "    train_folders = []\n",
    "    test_folders = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(files, labels)):\n",
    "        fold_train_dir = os.path.join(output_folder, f'fold_{fold+1}_train')\n",
    "        train_folders.append(fold_train_dir)\n",
    "        fold_test_dir = os.path.join(output_folder, f'fold_{fold+1}_val')\n",
    "        test_folders.append(fold_test_dir)\n",
    "        os.makedirs(fold_train_dir, exist_ok=True)\n",
    "        os.makedirs(fold_test_dir, exist_ok=True)\n",
    "        \n",
    "        for train_idx in train_index:\n",
    "            shutil.copy(files[train_idx], fold_train_dir)\n",
    "        for test_idx in test_index:\n",
    "            shutil.copy(files[test_idx], fold_test_dir)\n",
    "            \n",
    "    return train_folders, test_folders\n",
    "    \n",
    "train_folders, test_folders = stratified_k_fold_split(copied_als_folder, output_folder, n_splits=n_splits)"
   ],
   "id": "828540b56e86d123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({'FagSyl': 294, 'PseMen': 185, 'PinSyl': 141, 'PicAbi': 121, 'QueRub': 104, 'QuePet': 75})\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:29:44.941034Z",
     "start_time": "2024-12-10T17:29:44.930226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def poisson_subsample(las_file, min_distance=min_subsample_distance):\n",
    "    las = lp.read(las_file)\n",
    "    points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "\n",
    "    kdtree = cKDTree(points)\n",
    "\n",
    "    selected = np.zeros(len(points), dtype=bool)\n",
    "    selected_indices = []\n",
    "    for i, point in enumerate(points):\n",
    "        if selected[i]:\n",
    "            continue\n",
    "\n",
    "        selected_indices.append(i)\n",
    "        selected[i] = True\n",
    "\n",
    "        indices = kdtree.query_ball_point(point, min_distance)\n",
    "        selected[indices] = True\n",
    "\n",
    "    header = lp.LasHeader(point_format=las.header.point_format, version=las.header.version)\n",
    "    header.offsets = las.header.offsets\n",
    "    header.scales = las.header.scales\n",
    "\n",
    "    subsampled_las = lp.LasData(header)\n",
    "    subsampled_las.points = las.points[selected_indices]\n",
    "\n",
    "    subsampled_las.write(las_file)"
   ],
   "id": "d58dd06dcaa3137f",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:29:44.951776Z",
     "start_time": "2024-12-10T17:29:44.942858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_xy(las_file):\n",
    "        las = lp.read(las_file)\n",
    "        original_offset_x = las.header.offsets[0]\n",
    "        original_offset_y = las.header.offsets[1]\n",
    "        scale_x = las.header.scales[0]\n",
    "        scale_y = las.header.scales[1]\n",
    "\n",
    "        x = las.x\n",
    "        y = las.y\n",
    "\n",
    "        mean_x = np.mean(x)\n",
    "        mean_y = np.mean(y)\n",
    "        \n",
    "        # Normalize coordinates\n",
    "        normalized_x = x - mean_x\n",
    "        normalized_y = y - mean_y\n",
    "\n",
    "        new_header = lp.LasHeader(point_format=las.header.point_format, version=las.header.version)\n",
    "        new_header.scales = las.header.scales\n",
    "\n",
    "        new_header.offsets = [\n",
    "            original_offset_x - mean_x,\n",
    "            original_offset_y - mean_y,\n",
    "            las.header.offsets[2]  # Same z\n",
    "        ]\n",
    "\n",
    "        new_las = lp.LasData(new_header)\n",
    "        new_las.x = normalized_x\n",
    "        new_las.y = normalized_y\n",
    "        new_las.z = las.z\n",
    "\n",
    "        for dim_name in las.point_format.dimension_names:\n",
    "            if dim_name not in [\"X\", \"Y\", \"Z\"]:\n",
    "                setattr(new_las, dim_name, getattr(las, dim_name))\n",
    "\n",
    "        new_las.write(las_file)"
   ],
   "id": "f9127ad9978190d7",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:29:44.966208Z",
     "start_time": "2024-12-10T17:29:44.954159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rotate_z(pointcloud, degrees):\n",
    "    theta = np.deg2rad(degrees)\n",
    "\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(theta), -np.sin(theta), 0],\n",
    "        [np.sin(theta), np.cos(theta), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return np.dot(pointcloud, rotation_matrix.T)\n",
    "\n",
    "\n",
    "def rotate_las(las_file, rotations):\n",
    "        las = lp.read(las_file)\n",
    "\n",
    "        point_data = np.vstack((las.x, las.y, las.z)).T\n",
    "\n",
    "        for i, rotation in enumerate(rotations):\n",
    "\n",
    "            rotated_points = rotate_z(point_data, rotation)\n",
    "\n",
    "            header = lp.LasHeader(point_format=las.header.point_format, version=las.header.version)\n",
    "            header.offsets = las.header.offsets\n",
    "            header.scales = las.header.scales\n",
    "            # header.crs = lp.crs.CRS.from_epsg(25832)\n",
    "\n",
    "            rotated_las = lp.LasData(header)\n",
    "            rotated_las.x = rotated_points[:, 0]\n",
    "            rotated_las.y = rotated_points[:, 1]\n",
    "            rotated_las.z = rotated_points[:, 2]\n",
    "\n",
    "            for dim_name in las.point_format.dimension_names:\n",
    "                if dim_name not in [\"X\", \"Y\", \"Z\"]:\n",
    "                    setattr(rotated_las, dim_name, getattr(las, dim_name))\n",
    "\n",
    "            unique_filename = las_file.replace('.laz', f'_rot_{rotation}.laz')\n",
    "            output_filename = os.path.join(output_folder, unique_filename)\n",
    "\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            rotated_las.write(output_filename)"
   ],
   "id": "44f5634f32094f43",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:33:27.449119Z",
     "start_time": "2024-12-10T17:33:27.402953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Augment each folder\n",
    "\n",
    "def augmentation(train_folders=train_folders, test_folders=test_folders, \n",
    "                 redo_xy_normalization=False,\n",
    "                 redo_subsample=False,\n",
    "                 redo_rotation=False):\n",
    "\n",
    "    all_folders = train_folders + test_folders\n",
    "    for folder in all_folders:\n",
    "        for las_file in os.listdir(folder):\n",
    "            \n",
    "            # Normalize x,y by means\n",
    "            if redo_xy_normalization:\n",
    "                normalize_xy(las_file=os.path.join(folder, las_file))\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Downsample using minimum distance\n",
    "            if redo_subsample:\n",
    "                poisson_subsample(las_file=os.path.join(folder, las_file),\n",
    "                                  min_distance=min_subsample_distance)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Rotate on z-axis\n",
    "            if redo_rotation:\n",
    "                rotate_las(os.path.join(folder, las_file), rotations=rotations)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "augmentation()"
   ],
   "id": "b15af38c5b60886c",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T17:27:39.072089Z",
     "start_time": "2024-12-10T17:27:39.071832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to KPConv repository dataset format\n",
    "\n",
    "# Loop over each dataset and run trainNeuesPalaisTrees.py\n",
    "# Need to pass config parameters here and update class_w"
   ],
   "id": "aa91d6ed998cfc69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9305ff3b2ac4e93e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
